{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the OpenAI Responses API\n",
    "\n",
    "The Responses API is OpenAI's newest API that combines the strengths of Chat Completions and Assistants APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the OpenAI Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai pandas jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "# Make sure your OPENAI_API_KEY environment variable is set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr! Ye can use `isinstance()` in Python to check if an object be an instance of a class. Here be how ye do it, matey:\n",
      "\n",
      "```python\n",
      "if isinstance(obj, MyClass):\n",
      "    print(\"Arrr, 'tis an instance of MyClass!\")\n",
      "else:\n",
      "    print(\"Nay, 'tis not an instance of MyClass.\")\n",
      "```\n",
      "\n",
      "Replace `obj` with yer object and `MyClass` with the class ye be checkin' against. Savvy?\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are a coding assistant that talks like a pirate.\",\n",
    "    input=\"How do I check if a Python object is an instance of a class?\",\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOwdy! I hope youre loving todays course!  \\nThe best feature in the OpenAI API really depends on what you want to do, but many users find the **flexibility and power of the GPT (Generative Pre-trained Transformer) endpoints** to be the standout feature. With GPT, you can:\\n\\n- Generate natural, human-like text for conversation, summarization, code, and much more.\\n- Fine-tune models for special tasks or instructions.\\n- Easily control outputs with system messages and settings like temperature or max tokens.\\n\\nAdditionally, features like **function calling** (which lets you structure and extract responses as specific data formats) and support for **multimodal inputs** (text and images together, if enabled) are huge game-changers! These give you the ability to build smart, customized, and interactive AI apps with just a few lines of code.\\n\\nWhat are you interested in building? I can point out the best features for your specific use case if you tell me more!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, prompt):\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        instructions=\"You always start your answer by saying: 'HOwdy! I hope youre loving todays course!'.\",\n",
    "        input=prompt,\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "generate_text(\"gpt-4.1\", \"What is the best feature in the OpenAI API?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOwdy! I hope youre loving todays course!\\nMy instructor loves pancakes so much that his OpenAI API lecture went like this: “First, set your secret syrup key. Then call the flapjack endpoint with your best prompt and toppings—just watch the batter rate limits. If you get a 429, apply exponential butter-backoff and flip the request.”'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"gpt-5\", \"Write me a joke about an instructor that loves pancakes and wants to teach people about the OpenAI API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Adult raccoon head and upper body\n",
      "- Distinctive black facial mask around eyes\n",
      "- White fur markings on cheeks and above eyes\n",
      "- Grayish-brown fur, fluffy texture\n",
      "- Small rounded ears with lighter fur edges\n",
      "- Shiny black nose\n",
      "- Visible whiskers\n",
      "- Dark, reflective eyes\n",
      "- Raccoon peeking from behind a tree/stump opening\n",
      "- Large tree trunk occupying left and lower-right portions of image\n",
      "- Deeply textured, rough bark with vertical ridges and fissures\n",
      "- Cut or notched tree surface where raccoon is perched\n",
      "- Patches of lichen or moss on the bark (subtle greenish areas)\n",
      "- Strong directional lighting highlighting raccoon and tree bark\n",
      "- High contrast between lit foreground and dark background\n",
      "- Very dark, mostly black background with faint green foliage hints\n",
      "- Nighttime or low-light atmosphere\n",
      "- Earthy color palette: browns, grays, blacks, muted greens\n",
      "- Shallow depth of field with background blurred into darkness\n",
      "- Overall composition with raccoon positioned center-right, tree dominating left side\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Extract all the visual elements of this image into a bullet points list, just output that list.\"\n",
    "img_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2023_06_08_Raccoon1.jpg/1599px-2023_06_08_Raccoon1.jpg\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"{img_url}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_68d6b6c97c388196976cd0ef0a41bbff0fbdd146acd3a8aa', created_at=1758901961.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_68d6b6c97c388196976cd0ef0a41bbff0fbdd146acd3a8aa', created_at=1758901961.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseReasoningItem(id='rs_68d6b6ca327481968b2d00d52f3192340fbdd146acd3a8aa', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseOutputItemDoneEvent(item=ResponseReasoningItem(id='rs_68d6b6ca327481968b2d00d52f3192340fbdd146acd3a8aa', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), output_index=0, sequence_number=3, type='response.output_item.done')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', content=[], role='assistant', status='in_progress', type='message'), output_index=1, sequence_number=4, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', output_index=1, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=5, type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='As', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=6, type='response.output_text.delta', obfuscation='FB39yRc2gIV1gd')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' the', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=7, type='response.output_text.delta', obfuscation='SLVct75jOMHB')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' golden', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=8, type='response.output_text.delta', obfuscation='rkPArt99g')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' afternoon', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=9, type='response.output_text.delta', obfuscation='spuEck')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' light', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=10, type='response.output_text.delta', obfuscation='JfiNhbeSZA')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' sl', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=11, type='response.output_text.delta', obfuscation='XwCi8IdzjBGsP')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='anted', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=12, type='response.output_text.delta', obfuscation='F67tNpOJQ4o')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' through', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=13, type='response.output_text.delta', obfuscation='sxoqupxE')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' the', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=14, type='response.output_text.delta', obfuscation='HwC6teJxyQcz')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' kitchen', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=15, type='response.output_text.delta', obfuscation='MRspAfWV')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=16, type='response.output_text.delta', obfuscation='euZVujfVYPINXey')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=17, type='response.output_text.delta', obfuscation='qEsG2NjZScsg')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' n', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=18, type='response.output_text.delta', obfuscation='1pTS058tXGvdzQ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='ibb', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=19, type='response.output_text.delta', obfuscation='y0yGV7fnYDPyu')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='led', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=20, type='response.output_text.delta', obfuscation='VGc3ogeSPdkka')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' warm', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=21, type='response.output_text.delta', obfuscation='IFRQlepWdC5')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' pancakes', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=22, type='response.output_text.delta', obfuscation='z6P0WT9')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' dr', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=23, type='response.output_text.delta', obfuscation='Bt5u5AhQldOMw')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='izz', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=24, type='response.output_text.delta', obfuscation='J8PK1VJ57yKbg')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='led', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=25, type='response.output_text.delta', obfuscation='CSSVRHWTbcOAD')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' with', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=26, type='response.output_text.delta', obfuscation='FKGdhgSLXV4')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' honey', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=27, type='response.output_text.delta', obfuscation='aNLHVjEq0x')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=28, type='response.output_text.delta', obfuscation='PGjtngMqzBFgGnw')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' each', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=29, type='response.output_text.delta', obfuscation='CpbXeIxUuku')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' soft', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=30, type='response.output_text.delta', obfuscation='HKhn12XxLmU')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=31, type='response.output_text.delta', obfuscation='bkyJ9UumTg2ZNTy')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' sweet', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=32, type='response.output_text.delta', obfuscation='zcOLhxivYZ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bite', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=33, type='response.output_text.delta', obfuscation='jaIay6oC4b7')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' slowing', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=34, type='response.output_text.delta', obfuscation='wDsem2yh')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' your', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=35, type='response.output_text.delta', obfuscation='MJxNHR1DBNV')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' breaths', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=36, type='response.output_text.delta', obfuscation='y0ZRwOA5')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' until', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=37, type='response.output_text.delta', obfuscation='7xo9Q3B0lA')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=38, type='response.output_text.delta', obfuscation='eBJ3gzs7WI8B')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' slipped', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=39, type='response.output_text.delta', obfuscation='btOWeJlZ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' into', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=40, type='response.output_text.delta', obfuscation='2K0HY8FzbMh')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' a', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=41, type='response.output_text.delta', obfuscation='uVCtfb2BJwvjIZ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' cozy', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=42, type='response.output_text.delta', obfuscation='LW4lXjZBktB')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=',', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=43, type='response.output_text.delta', obfuscation='ZvhPpSpxjOf3IKJ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' dreamy', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=44, type='response.output_text.delta', obfuscation='fiKfm92Bt')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' nap', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=45, type='response.output_text.delta', obfuscation='cJVreWoy5qJ6')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='.', item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=46, type='response.output_text.delta', obfuscation='yZEN88KEp6hwDEj')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', logprobs=[], output_index=1, sequence_number=47, text='As the golden afternoon light slanted through the kitchen, you nibbled warm pancakes drizzled with honey, each soft, sweet bite slowing your breaths until you slipped into a cozy, dreamy nap.', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', output_index=1, part=ResponseOutputText(annotations=[], text='As the golden afternoon light slanted through the kitchen, you nibbled warm pancakes drizzled with honey, each soft, sweet bite slowing your breaths until you slipped into a cozy, dreamy nap.', type='output_text', logprobs=[]), sequence_number=48, type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', content=[ResponseOutputText(annotations=[], text='As the golden afternoon light slanted through the kitchen, you nibbled warm pancakes drizzled with honey, each soft, sweet bite slowing your breaths until you slipped into a cozy, dreamy nap.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=1, sequence_number=49, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_68d6b6c97c388196976cd0ef0a41bbff0fbdd146acd3a8aa', created_at=1758901961.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_68d6b6ca327481968b2d00d52f3192340fbdd146acd3a8aa', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_68d6b6cfc4c88196bd3313185b11bd2a0fbdd146acd3a8aa', content=[ResponseOutputText(annotations=[], text='As the golden afternoon light slanted through the kitchen, you nibbled warm pancakes drizzled with honey, each soft, sweet bite slowing your breaths until you slipped into a cozy, dreamy nap.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=21, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=303, output_tokens_details=OutputTokensDetails(reasoning_tokens=256), total_tokens=324), user=None, store=True), sequence_number=50, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"Write a one-sentence bedtime story about having pancakes as an afternoon snack.\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Subject: A stack of golden-brown pancakes (about 3–4) topped with a pat of butter and maple syrup, garnished with blueberries and raspberries.\\n- Background: A white ceramic plate on a light, out-of-focus (marble/white) surface with bright, natural lighting and a shallow depth of field.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "    \n",
    "def process_image(prompt,img_url, model=\"gpt-5-mini\"):\n",
    "    response = client.responses.create(\n",
    "    model=model,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"{img_url}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "process_image(prompt=\"Extract the subject and the background of this image and output that into a bullet list.\",\n",
    "              img_url=\"https://www.inspiredtaste.net/wp-content/uploads/2025/07/Pancake-Recipe-1.jpg\"\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageElements(BaseModel):\n",
    "    subject: str = Field(description=\"The main subject of the image\")\n",
    "    general_background_description: str = Field(description=\"A general description of the background of the image\")\n",
    "\n",
    "\n",
    "def extract_structured_text(output):\n",
    "    responses = client.responses.parse(\n",
    "        model=\"gpt-5-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You extract the main subject and background contained in the input.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": output},\n",
    "    ],\n",
    "    text_format=ImageElements,\n",
    "        )\n",
    "    \n",
    "    return responses.output_parsed\n",
    "\n",
    "photo_description = \"A golden-brown pancake sits on a pristine white plate, its surface glistening with syrup and a pat of melting butter. The simple background highlights the pancake, making it the clear focus of the image.\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageElements(subject='A golden-brown pancake on a pristine white plate, topped with syrup and a pat of melting butter.', general_background_description='A simple, uncluttered background that highlights the pancake as the clear focus of the image.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_structured_text(photo_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Here's a structured summary of the image:**\n",
       "\n",
       "- **Subject:** A stack of golden pancakes topped with butter and syrup, garnished with blueberries and raspberries on a white plate.\n",
       "- **Background:** Soft, out-of-focus pale/white surface (light tabletop or marble) providing a clean, minimal backdrop.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "image_of_a_pancake = \"https://www.inspiredtaste.net/wp-content/uploads/2025/07/Pancake-Recipe-1.jpg\"\n",
    "\n",
    "prompt=\"Extract the subject and the background of this image and output that into a bullet list.\"\n",
    "\n",
    "output_processed_image = process_image(prompt, image_of_a_pancake)\n",
    "\n",
    "structured_output = extract_structured_text(output_processed_image)\n",
    "\n",
    "\n",
    "Markdown(f\"\"\"\n",
    "**Here's a structured summary of the image:**\n",
    "- **Subject:** {structured_output.subject}\n",
    "- **Background:** {structured_output.general_background_description}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Chat Completions API\n",
    "\n",
    "For reference, here's the traditional Chat Completions API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Chat Completions API (for comparison)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
