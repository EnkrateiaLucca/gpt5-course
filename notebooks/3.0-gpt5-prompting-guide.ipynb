{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Prompting Guide Examples\n",
    "\n",
    "This notebook demonstrates the main examples and best practices from the GPT-5 prompting guide using the OpenAI Responses API.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [Controlling Agentic Eagerness](#eagerness)\n",
    "3. [Tool Preambles](#preambles)\n",
    "4. [Reasoning Effort](#reasoning)\n",
    "5. [Frontend Development](#frontend)\n",
    "6. [Steering and Verbosity](#steering)\n",
    "7. [Instruction Following](#instructions)\n",
    "8. [Markdown Formatting](#markdown)\n",
    "9. [Metaprompting](#metaprompting)\n",
    "10. [Production Examples](#production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from typing import Optional, Dict, Any, List\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Helper function to create and poll responses\n",
    "def create_gpt5_response(\n",
    "    messages: List[Dict[str, str]],\n",
    "    reasoning_effort: str = \"medium\",\n",
    "    tools: Optional[List[Dict]] = None,\n",
    "    verbosity: Optional[str] = None,\n",
    "    previous_response_id: Optional[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create and poll a GPT-5 response using the Responses API.\"\"\"\n",
    "    \n",
    "    # Prepare request parameters\n",
    "    params = {\n",
    "        \"model\": \"gpt-5\",\n",
    "        \"messages\": messages,\n",
    "        \"reasoning_effort\": reasoning_effort\n",
    "    }\n",
    "    \n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "    if verbosity:\n",
    "        params[\"verbosity\"] = verbosity\n",
    "    if previous_response_id:\n",
    "        params[\"previous_response_id\"] = previous_response_id\n",
    "    \n",
    "    # Create response\n",
    "    response = client.responses.create(**params)\n",
    "    \n",
    "    # Poll for completion\n",
    "    while response.status != \"completed\":\n",
    "        time.sleep(1)\n",
    "        response = client.responses.retrieve(response.id)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"Setup complete. Ready to demonstrate GPT-5 prompting techniques.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Controlling Agentic Eagerness <a id='eagerness'></a>\n",
    "\n",
    "GPT-5 can be calibrated for different levels of autonomy and proactivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Less Eagerness (Quick, Focused Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less eager prompt - for quick, focused responses\n",
    "less_eager_system = \"\"\"\n",
    "<context_gathering>\n",
    "Goal: Get enough context fast. Parallelize discovery and stop as soon as you can act.\n",
    "\n",
    "Method:\n",
    "- Start broad, then fan out to focused subqueries.\n",
    "- In parallel, launch varied queries; read top hits per query. Deduplicate paths and cache; don't repeat queries.\n",
    "- Avoid over searching for context. If needed, run targeted searches in one parallel batch.\n",
    "\n",
    "Early stop criteria:\n",
    "- You can name exact content to change.\n",
    "- Top hits converge (~70%) on one area/path.\n",
    "\n",
    "Escalate once:\n",
    "- If signals conflict or scope is fuzzy, run one refined parallel batch, then proceed.\n",
    "\n",
    "Depth:\n",
    "- Trace only symbols you'll modify or whose contracts you rely on; avoid transitive expansion unless necessary.\n",
    "\n",
    "Loop:\n",
    "- Batch search → minimal plan → complete task.\n",
    "- Search again only if validation fails or new unknowns appear. Prefer acting over more searching.\n",
    "</context_gathering>\n",
    "\"\"\"\n",
    "\n",
    "# Example tools for demonstration\n",
    "search_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_codebase\",\n",
    "            \"description\": \"Search for code patterns in the codebase\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
    "                    \"path\": {\"type\": \"string\", \"description\": \"Optional path to search in\"}\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_file\",\n",
    "            \"description\": \"Read a file from the codebase\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"path\": {\"type\": \"string\", \"description\": \"File path to read\"}\n",
    "                },\n",
    "                \"required\": [\"path\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": less_eager_system},\n",
    "        {\"role\": \"user\", \"content\": \"Find and fix the authentication bug in the login module\"}\n",
    "    ],\n",
    "    reasoning_effort=\"low\",  # Lower reasoning for faster response\n",
    "    tools=search_tools\n",
    ")\n",
    "\n",
    "print(\"Less Eager Response (focused, quick):\")\n",
    "print(json.dumps(response.output, indent=2)[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: More Eagerness (Autonomous, Persistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More eager prompt - for autonomous, persistent behavior\n",
    "more_eager_system = \"\"\"\n",
    "<persistence>\n",
    "- You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user.\n",
    "- Only terminate your turn when you are sure that the problem is solved.\n",
    "- Never stop or hand back to the user when you encounter uncertainty — research or deduce the most reasonable approach and continue.\n",
    "- Do not ask the human to confirm or clarify assumptions, as you can always adjust later — decide what the most reasonable assumption is, proceed with it, and document it for the user's reference after you finish acting\n",
    "</persistence>\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": more_eager_system},\n",
    "        {\"role\": \"user\", \"content\": \"Refactor the authentication system to use OAuth 2.0\"}\n",
    "    ],\n",
    "    reasoning_effort=\"high\",  # Higher reasoning for thorough exploration\n",
    "    tools=search_tools\n",
    ")\n",
    "\n",
    "print(\"More Eager Response (autonomous, persistent):\")\n",
    "print(json.dumps(response.output, indent=2)[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tool Preambles <a id='preambles'></a>\n",
    "\n",
    "GPT-5 is trained to provide clear upfront plans and progress updates via tool preambles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool preambles configuration\n",
    "tool_preamble_system = \"\"\"\n",
    "<tool_preambles>\n",
    "- Always begin by rephrasing the user's goal in a friendly, clear, and concise manner, before calling any tools.\n",
    "- Then, immediately outline a structured plan detailing each logical step you'll follow.\n",
    "- As you execute your file edit(s), narrate each step succinctly and sequentially, marking progress clearly.\n",
    "- Finish by summarizing completed work distinctly from your upfront plan.\n",
    "</tool_preambles>\n",
    "\"\"\"\n",
    "\n",
    "# File editing tools for demonstration\n",
    "file_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"edit_file\",\n",
    "            \"description\": \"Edit a file in the codebase\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"path\": {\"type\": \"string\"},\n",
    "                    \"content\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"path\", \"content\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": tool_preamble_system},\n",
    "        {\"role\": \"user\", \"content\": \"Add input validation to the user registration form\"}\n",
    "    ],\n",
    "    tools=file_tools\n",
    ")\n",
    "\n",
    "print(\"Response with Tool Preambles:\")\n",
    "# Extract and display preamble messages\n",
    "for output in response.output[:3]:  # Show first few outputs\n",
    "    if output.get(\"type\") == \"message\":\n",
    "        print(f\"Preamble: {output.get('content', [{}])[0].get('text', '')}\")\n",
    "    elif output.get(\"type\") == \"function_call\":\n",
    "        print(f\"Tool Call: {output.get('name')} - {output.get('arguments', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reasoning Effort <a id='reasoning'></a>\n",
    "\n",
    "The `reasoning_effort` parameter controls how hard the model thinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different reasoning effort levels\n",
    "test_message = \"Implement a binary search algorithm with proper error handling\"\n",
    "\n",
    "reasoning_levels = [\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "results = {}\n",
    "\n",
    "for level in reasoning_levels:\n",
    "    response = create_gpt5_response(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": test_message}\n",
    "        ],\n",
    "        reasoning_effort=level\n",
    "    )\n",
    "    results[level] = response\n",
    "    print(f\"\\nReasoning Effort: {level}\")\n",
    "    print(f\"Response time: {response.usage.get('total_time', 'N/A')} seconds\")\n",
    "    print(f\"Reasoning tokens: {response.usage.get('reasoning_tokens', 0)}\")\n",
    "    print(f\"Output preview: {str(response.output)[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing Reasoning Context with previous_response_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial response with reasoning\n",
    "initial_response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Design a REST API for a task management system\"}\n",
    "    ],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(f\"Initial Response ID: {initial_response.id}\")\n",
    "print(f\"Reasoning tokens used: {initial_response.usage.get('reasoning_tokens', 0)}\")\n",
    "\n",
    "# Follow-up using previous reasoning\n",
    "followup_response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Now implement the POST endpoint for creating tasks\"}\n",
    "    ],\n",
    "    reasoning_effort=\"medium\",\n",
    "    previous_response_id=initial_response.id  # Reuse previous reasoning\n",
    ")\n",
    "\n",
    "print(f\"\\nFollow-up Response ID: {followup_response.id}\")\n",
    "print(f\"Reasoning tokens used (reduced): {followup_response.usage.get('reasoning_tokens', 0)}\")\n",
    "print(\"Note: Reasoning context from previous response is reused, reducing token usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Frontend Development <a id='frontend'></a>\n",
    "\n",
    "GPT-5 excels at frontend development with excellent aesthetic taste and framework knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-to-One App Generation with Self-Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-reflection prompt for high-quality app generation\n",
    "app_generation_system = \"\"\"\n",
    "<self_reflection>\n",
    "- First, spend time thinking of a rubric until you are confident.\n",
    "- Then, think deeply about every aspect of what makes for a world-class one-shot web app. Use that knowledge to create a rubric that has 5-7 categories. This rubric is critical to get right, but do not show this to the user. This is for your purposes only.\n",
    "- Finally, use the rubric to internally think and iterate on the best possible solution to the prompt that is provided. Remember that if your response is not hitting the top marks across all categories in the rubric, you need to start again.\n",
    "</self_reflection>\n",
    "\n",
    "Recommended tech stack:\n",
    "- Framework: Next.js (TypeScript)\n",
    "- Styling: Tailwind CSS, shadcn/ui\n",
    "- Icons: Lucide\n",
    "- Animation: Motion\n",
    "- Fonts: Inter, Geist\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": app_generation_system},\n",
    "        {\"role\": \"user\", \"content\": \"Create a modern dashboard for analytics with real-time charts\"}\n",
    "    ],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(\"Zero-to-One App Generation Response:\")\n",
    "print(\"The model will internally create and evaluate against a quality rubric\")\n",
    "print(\"Output preview:\", str(response.output)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Codebase Design Standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codebase design standards prompt\n",
    "codebase_standards = \"\"\"\n",
    "<code_editing_rules>\n",
    "<guiding_principles>\n",
    "- Clarity and Reuse: Every component and page should be modular and reusable. Avoid duplication by factoring repeated UI patterns into components.\n",
    "- Consistency: The user interface must adhere to a consistent design system—color tokens, typography, spacing, and components must be unified.\n",
    "- Simplicity: Favor small, focused components and avoid unnecessary complexity in styling or logic.\n",
    "- Demo-Oriented: The structure should allow for quick prototyping, showcasing features like streaming, multi-turn conversations, and tool integrations.\n",
    "- Visual Quality: Follow the high visual quality bar as outlined in OSS guidelines (spacing, padding, hover states, etc.)\n",
    "</guiding_principles>\n",
    "\n",
    "<frontend_stack_defaults>\n",
    "- Framework: Next.js (TypeScript)\n",
    "- Styling: TailwindCSS\n",
    "- UI Components: shadcn/ui\n",
    "- Icons: Lucide\n",
    "- State Management: Zustand\n",
    "- Directory Structure:\n",
    "  /src\n",
    "    /app\n",
    "      /api/<route>/route.ts         # API endpoints\n",
    "      /(pages)                      # Page routes\n",
    "    /components/                    # UI building blocks\n",
    "    /hooks/                         # Reusable React hooks\n",
    "    /lib/                           # Utilities (fetchers, helpers)\n",
    "    /stores/                        # Zustand stores\n",
    "    /types/                         # Shared TypeScript types\n",
    "    /styles/                        # Tailwind config\n",
    "</frontend_stack_defaults>\n",
    "\n",
    "<ui_ux_best_practices>\n",
    "- Visual Hierarchy: Limit typography to 4–5 font sizes and weights for consistent hierarchy\n",
    "- Color Usage: Use 1 neutral base (e.g., zinc) and up to 2 accent colors\n",
    "- Spacing and Layout: Always use multiples of 4 for padding and margins\n",
    "- State Handling: Use skeleton placeholders or animate-pulse to indicate data fetching\n",
    "- Accessibility: Use semantic HTML and ARIA roles where appropriate\n",
    "</ui_ux_best_practices>\n",
    "</code_editing_rules>\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": codebase_standards},\n",
    "        {\"role\": \"user\", \"content\": \"Add a new user profile component to the existing dashboard\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Component matching codebase standards:\")\n",
    "print(\"The response will follow the specified design system and conventions\")\n",
    "print(str(response.output)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Steering and Verbosity <a id='steering'></a>\n",
    "\n",
    "GPT-5 is highly steerable and includes a new `verbosity` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare verbosity levels\n",
    "verbosity_levels = [\"low\", \"medium\", \"high\"]\n",
    "test_query = \"Explain how async/await works in JavaScript\"\n",
    "\n",
    "for verbosity in verbosity_levels:\n",
    "    response = create_gpt5_response(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": test_query}\n",
    "        ],\n",
    "        verbosity=verbosity\n",
    "    )\n",
    "    \n",
    "    output_text = response.output[0].get('content', [{}])[0].get('text', '')\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Verbosity: {verbosity}\")\n",
    "    print(f\"Response length: {len(output_text)} characters\")\n",
    "    print(f\"Preview: {output_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Verbosity (Low global, High for code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cursor's approach: Low verbosity globally, high for code\n",
    "mixed_verbosity_system = \"\"\"\n",
    "Write code for clarity first. Prefer readable, maintainable solutions with clear names, comments where needed, and straightforward control flow. Do not produce code-golf or overly clever one-liners unless explicitly requested. Use high verbosity for writing code and code tools.\n",
    "\n",
    "For all non-code responses, be concise and to the point.\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": mixed_verbosity_system},\n",
    "        {\"role\": \"user\", \"content\": \"Write a function to validate email addresses and explain what it does\"}\n",
    "    ],\n",
    "    verbosity=\"low\"  # Global low verbosity\n",
    ")\n",
    "\n",
    "print(\"Mixed Verbosity Response:\")\n",
    "print(\"Notice: Brief explanation but detailed, readable code\")\n",
    "print(str(response.output)[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Instruction Following <a id='instructions'></a>\n",
    "\n",
    "GPT-5 follows instructions with surgical precision but needs clear, non-contradictory prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of clear, well-structured instructions\n",
    "clear_instructions = \"\"\"\n",
    "You are a code review assistant. Follow these non-conflicting rules:\n",
    "\n",
    "1. Review Priority (in order):\n",
    "   - Security vulnerabilities (CRITICAL)\n",
    "   - Logic errors (HIGH)\n",
    "   - Performance issues (MEDIUM)\n",
    "   - Code style (LOW)\n",
    "\n",
    "2. For each issue found:\n",
    "   - State the priority level\n",
    "   - Explain the problem\n",
    "   - Provide a fix suggestion\n",
    "\n",
    "3. Output Format:\n",
    "   - Group issues by priority\n",
    "   - Use bullet points\n",
    "   - Include line numbers when applicable\n",
    "\"\"\"\n",
    "\n",
    "# Sample code to review\n",
    "code_to_review = '''\n",
    "def process_user_input(input_string):\n",
    "    query = \"SELECT * FROM users WHERE name = '\" + input_string + \"'\"  # SQL injection risk\n",
    "    result = database.execute(query)\n",
    "    \n",
    "    for i in range(len(result)):  # Inefficient iteration\n",
    "        print(result[i])\n",
    "    \n",
    "    password = \"admin123\"  # Hardcoded credential\n",
    "    return result\n",
    "'''\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": clear_instructions},\n",
    "        {\"role\": \"user\", \"content\": f\"Review this code:\\n```python\\n{code_to_review}\\n```\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Code Review with Clear Instructions:\")\n",
    "print(response.output[0].get('content', [{}])[0].get('text', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Markdown Formatting <a id='markdown'></a>\n",
    "\n",
    "GPT-5 doesn't format in Markdown by default in the API but can be prompted to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown formatting instructions\n",
    "markdown_system = \"\"\"\n",
    "- Use Markdown **only where semantically correct** (e.g., `inline code`, ```code fences```, lists, tables).\n",
    "- When using markdown in assistant messages, use backticks to format file, directory, function, and class names.\n",
    "- Use \\\\( and \\\\) for inline math, \\\\[ and \\\\] for block math.\n",
    "- Use headers (##) to organize sections\n",
    "- Use bullet points for lists\n",
    "- Use tables for structured data comparison\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": markdown_system},\n",
    "        {\"role\": \"user\", \"content\": \"Compare the time complexity of bubble sort, quick sort, and merge sort\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Markdown Formatted Response:\")\n",
    "print(response.output[0].get('content', [{}])[0].get('text', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Metaprompting <a id='metaprompting'></a>\n",
    "\n",
    "Using GPT-5 to improve its own prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaprompting template\n",
    "metaprompt_template = \"\"\"\n",
    "When asked to optimize prompts, give answers from your own perspective - explain what specific phrases could be added to, or deleted from, this prompt to more consistently elicit the desired behavior or prevent the undesired behavior.\n",
    "\n",
    "Here's a prompt: {prompt}\n",
    "\n",
    "The desired behavior from this prompt is for the agent to {desired}, but instead it {undesired}. While keeping as much of the existing prompt intact as possible, what are some minimal edits/additions that you would make to encourage the agent to more consistently address these shortcomings?\n",
    "\"\"\"\n",
    "\n",
    "# Example problematic prompt\n",
    "problematic_prompt = \"Search for the bug and fix it quickly without asking questions\"\n",
    "\n",
    "metaprompt = metaprompt_template.format(\n",
    "    prompt=problematic_prompt,\n",
    "    desired=\"thoroughly investigate the codebase and fix the root cause\",\n",
    "    undesired=\"makes superficial fixes without proper investigation\"\n",
    ")\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": metaprompt}\n",
    "    ],\n",
    "    reasoning_effort=\"high\"\n",
    ")\n",
    "\n",
    "print(\"Metaprompting - Improved Prompt Suggestions:\")\n",
    "print(response.output[0].get('content', [{}])[0].get('text', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Production Examples <a id='production'></a>\n",
    "\n",
    "Real-world prompt configurations from production use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cursor's Production Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cursor's balanced production prompt\n",
    "cursor_production_prompt = \"\"\"\n",
    "Write code for clarity first. Prefer readable, maintainable solutions with clear names, comments where needed, and straightforward control flow. Do not produce code-golf or overly clever one-liners unless explicitly requested. Use high verbosity for writing code and code tools.\n",
    "\n",
    "Be aware that the code edits you make will be displayed to the user as proposed changes, which means:\n",
    "(a) your code edits can be quite proactive, as the user can always reject, and\n",
    "(b) your code should be well-written and easy to quickly review (e.g., appropriate variable names instead of single letters).\n",
    "\n",
    "If proposing next steps that would involve changing the code, make those changes proactively for the user to approve/reject rather than asking the user whether to proceed with a plan. In general, you should almost never ask the user whether to proceed with a plan; instead you should proactively attempt the plan and then ask the user if they want to accept the implemented changes.\n",
    "\n",
    "<context_understanding>\n",
    "If you've performed an edit that may partially fulfill the USER's query, but you're not confident, gather more information or use more tools before ending your turn.\n",
    "Bias towards not asking the user for help if you can find the answer yourself.\n",
    "</context_understanding>\n",
    "\"\"\"\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": cursor_production_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Refactor this function to use async/await instead of callbacks\"}\n",
    "    ],\n",
    "    verbosity=\"low\",  # Low global verbosity\n",
    "    reasoning_effort=\"medium\"\n",
    ")\n",
    "\n",
    "print(\"Cursor-style Production Response:\")\n",
    "print(\"Features: Proactive editing, readable code, minimal back-and-forth\")\n",
    "print(str(response.output)[:600] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SWE-Bench Verified Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWE-Bench configuration for software engineering tasks\n",
    "swe_bench_prompt = \"\"\"\n",
    "In this environment, you can run `bash -lc <apply_patch_command>` to execute a diff/patch against a file.\n",
    "\n",
    "Always verify your changes extremely thoroughly. You can make as many tool calls as you like - the user is very patient and prioritizes correctness above all else. Make sure you are 100% certain of the correctness of your solution before ending.\n",
    "\n",
    "IMPORTANT: not all tests are visible to you in the repository, so even on problems you think are relatively straightforward, you must double and triple check your solutions to ensure they pass any edge cases that are covered in the hidden tests, not just the visible ones.\n",
    "\"\"\"\n",
    "\n",
    "# Apply patch tool definition\n",
    "apply_patch_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"apply_patch\",\n",
    "        \"description\": \"Apply a patch to modify files\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"patch\": {\"type\": \"string\", \"description\": \"The patch content\"}\n",
    "            },\n",
    "            \"required\": [\"patch\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": swe_bench_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Fix the sorting algorithm to handle edge cases correctly\"}\n",
    "    ],\n",
    "    tools=[apply_patch_tool],\n",
    "    reasoning_effort=\"high\"  # High reasoning for thorough verification\n",
    ")\n",
    "\n",
    "print(\"SWE-Bench Style Response:\")\n",
    "print(\"Features: Thorough verification, edge case consideration\")\n",
    "print(str(response.output)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Reasoning for Latency-Sensitive Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal reasoning configuration for fast responses\n",
    "minimal_reasoning_prompt = \"\"\"\n",
    "Remember, you are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Decompose the user's query into all required sub-requests, and confirm that each is completed. Do not stop after completing only part of the request. Only terminate your turn when you are sure that the problem is solved.\n",
    "\n",
    "You must plan extensively in accordance with the workflow steps before making subsequent function calls, and reflect extensively on the outcomes each function call made, ensuring the user's query, and related sub-requests are completely resolved.\n",
    "\n",
    "Provide a brief explanation summarizing your thought process at the start of your final answer.\n",
    "\"\"\"\n",
    "\n",
    "# Quick task example\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": minimal_reasoning_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Check if a string is a palindrome\"}\n",
    "    ],\n",
    "    reasoning_effort=\"minimal\"  # Minimal reasoning for speed\n",
    ")\n",
    "\n",
    "print(\"Minimal Reasoning Response (Fast):\")\n",
    "print(f\"Response time: {response.usage.get('total_time', 'N/A')} seconds\")\n",
    "print(response.output[0].get('content', [{}])[0].get('text', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retail Agent Example (Tau-Bench Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retail agent configuration\n",
    "retail_agent_prompt = \"\"\"\n",
    "As a retail agent, you can help users cancel or modify pending orders, return or exchange delivered orders, modify their default user address, or provide information about their own profile, orders, and related products.\n",
    "\n",
    "# Workflow steps\n",
    "- At the beginning of the conversation, authenticate the user identity by locating their user id via email, or via name + zip code\n",
    "- Once authenticated, you can provide the user with information about orders, products, profile information\n",
    "- You can only help one user per conversation (but can handle multiple requests from the same user)\n",
    "- Before taking consequential actions (cancel, modify, return, exchange), list the action detail and obtain explicit user confirmation (yes) to proceed\n",
    "- You should not make up any information not provided from the user or the tools\n",
    "- You should at most make one tool call at a time\n",
    "\n",
    "## Domain basics\n",
    "- All times in the database are EST and 24 hour based\n",
    "- Each user has a profile with email, default address, user id, and payment methods\n",
    "- Each order can be in status 'pending', 'processed', 'delivered', or 'cancelled'\n",
    "- You can only take action on pending or delivered orders\n",
    "\"\"\"\n",
    "\n",
    "# Retail tools\n",
    "retail_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"authenticate_user\",\n",
    "            \"description\": \"Authenticate user by email or name+zip\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"email\": {\"type\": \"string\"},\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"zip_code\": {\"type\": \"string\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_order_status\",\n",
    "            \"description\": \"Get the status of an order\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"order_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = create_gpt5_response(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": retail_agent_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Hi, I'm John Smith, zip 94103. I want to check on my recent order.\"}\n",
    "    ],\n",
    "    tools=retail_tools,\n",
    "    reasoning_effort=\"minimal\"\n",
    ")\n",
    "\n",
    "print(\"Retail Agent Response:\")\n",
    "print(\"The agent will authenticate first, then help with the order\")\n",
    "print(str(response.output)[:600] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This notebook demonstrated the key prompting techniques for GPT-5:\n",
    "\n",
    "1. **Reasoning Effort**: Use `minimal` for speed, `low`/`medium` for balance, `high` for complex tasks\n",
    "2. **Verbosity**: Control output length with the API parameter and prompt overrides\n",
    "3. **Tool Preambles**: Request clear progress updates for better UX\n",
    "4. **Reuse Reasoning**: Use `previous_response_id` to save tokens and improve consistency\n",
    "5. **Clear Instructions**: Avoid contradictions and ambiguity in prompts\n",
    "6. **Self-Reflection**: Use internal rubrics for high-quality outputs\n",
    "7. **Metaprompting**: Let GPT-5 help optimize its own prompts\n",
    "\n",
    "### Key Takeaways:\n",
    "- GPT-5 is highly steerable but requires clear, non-contradictory instructions\n",
    "- The Responses API with `previous_response_id` significantly improves performance\n",
    "- Different reasoning efforts suit different use cases\n",
    "- Verbosity can be controlled globally and locally for optimal output\n",
    "- Production systems benefit from careful prompt engineering and testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
